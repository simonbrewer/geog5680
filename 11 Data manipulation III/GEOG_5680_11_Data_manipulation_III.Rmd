---
title: "GEOG 5680 6680 11 Data manipulation III"
author: | 
  | Simon Brewer
  | Geography Department
  | University of Utah
date: "May 05, 2021"
output:
  html_document:
    toc: true
    toc_float: true
    fig_caption: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(png)
library(grid)
```

## Introduction

We have previously look at processing and manipulating data in R using basic functions and **dplyr**. In this lab, we'll introduce a third method using **data.table**. This package is provides a different implementation of the data frames that we have been using so far, designed to work with large datasets (>100GB in RAM). It does this by a number of methods: making certain low-level function parallel (i.e. run on multiple cores of your computer) and more efficient referencing of the file in memory. It also provides a way to manipulate and subset data that is based on the functions available in Structured Query Language (SQL) commonly used with databases.

Remember to use RStudio's script editor (top left panel) to enter your commands and then copy-paste these to the console when you are ready. This will keep a copy of the commands that you can save and return to. 

Before starting, remember to create a working directory (e.g. `module11`). Next download the files for today's lab from the Canvas page and move them to this directory. You'll need the following file:

- *flights14.csv*
- *iris.csv*
- *Temperature.csv*

Then start RStudio, and change your working directory from the [Session] menu > [Set working directory] > [Choose directory...]. Remember to check that R can see the files by running the `list.files()` command. 

The examples below borrow heavily from the **data.table** introductory vignette, and illustrate how to efficiently import data, the `data.table` syntax, its general form, how to *subset* rows, *select and compute* on columns, and perform aggregations *by group*. 

The **data.table** package should already be installed with your version of R, so load it now:

```{r message=FALSE}
library(data.table)
```

If it is not installed, do so now with `install.packages()` or the [Install] button from the Packages tab. If you are using a Mac, you may see a warning message when you load the package saying that it did not detect OpenMP support. You can ignore this for now. Instructions for adding this (which enables parallel operations) can be found [here][dtmacID]

The dataset we will use contains a list of all the flights that departed from New York City airports between January and October 2014, taken from the [Bureau of Transporation Statistics][btsID]. This is not a massive file, but still has about 250K observations. Let's read this now using **data.table**'s fast-and-friendly file reader `fread`:

```{r}
flights <- fread("flights14.csv")
dim(flights)
class(flights)
```

The output of the `class()` function tells us that the data have been read in as a `data.table`, which inherits functions from `data.frame`. Note that `fread()` will also take a web address as input, if you need to read a file directly from a url. For example, to get the flight data directly from the source, you could run:

```{r eval=FALSE}
flights <- fread("https://raw.githubusercontent.com/Rdatatable/data.table/master/vignettes/flights14.csv")
```

Let's take a quick look at the data. You can use `str()` as we have before, or the `head()` command to see the first few rows. However, if you simply type the name of the new object (`flights`), it will print out a nicely formatted view of the first and last few rows:

```{r}
flights
```

Note that you can also create a `data.table` using the `data.table()` function: 
```{r}
DT = data.table(
  ID = c("b","b","b","a","a","c"),
  a = 1:6,
  b = 7:12,
  c = 13:18
)
DT
class(DT$ID)
```

Existing R objects can be converted to a `data.table` using `setDT()` (for `data.frame`s and `list`s) and `as.data.table()` (for other structures). For example, if we read in the iris dataset into a data frame, we can then convert it as follows:

```{r}
iris <- read.csv("iris.csv")
class(iris)
setDT(iris)
class(iris)
iris
```

In contrast to a `data.frame`, where we use indices within the `[ ... ]` to subset rows and select columns, you can do *a lot more* with a `data.table`. We'll start with the general `data.table` syntax:

```{r eval = FALSE}
DT[i, j, by]
```

If you have previously used SQL, there is a direct comparison between these elements (`i, j, by`) and SQL syntax:

```
##   R:                 i                 j        by
## SQL:  where | order by   select | update  group by
```

This can be read as:

> Using `DT`, subset/reorder rows using `i`, then calculate `j`, grouped by `by`.

Let's begin by looking at `i` and `j` first - subsetting rows and operating on columns.

### Subset rows by `i`

a) Get all the flights with "JFK" as the origin airport in the month of June.

```{r}
ans <- flights[origin == "JFK" & month == 6]
head(ans)
```

Much like **dplyr**, column names can be referred directly, and you don't need to add the prefix `flights$` each time. 

Note that if we were doing the same thing with dataframe, we'd need to put a comma after the condition, to indicate that we are selecting rows. Here, the comma is not necessary (but this will still work if you include it).

b) Get the first two rows from `flights`

```{r}
ans <- flights[1:2]
ans
```

c) Sort `flights` first by column `origin` in *ascending* order, and then by `dest` in *descending* order (this uses a much more efficient version of the `order()` function in base R:

```{r}
ans <- flights[order(origin, -dest)]
head(ans)
```

### Select column(s) by `j`

a) Select `arr_delay` column, but return it as a *vector* (this returns all the rows for this column)

```{r}
ans <- flights[, arr_delay]
head(ans)
```

b) We'll do the same selection (`arr_delay`). But if we wrap the required *variables* (column names) in a `list()`, the output is a `data.table` instead of a vector.  

```{r}
ans <- flights[, list(arr_delay)]
head(ans)
```

Note that you can use `.()` as a shorthand for `list()` here:

```{r}
ans <- flights[, .(arr_delay)]
head(ans)
```

Note that as long as `j-expression` returns a `list`, each element of the list will be converted to a column in the resulting `data.table`. This makes `j` quite powerful, as we will see shortly. It is also very important to understand this for when you'd like to make more complicated queries.

c) Select both `arr_delay` and `dep_delay` columns.

```{r}
ans <- flights[, .(arr_delay, dep_delay)]
head(ans)
```

d) Note that we can rename the selected variables in the list:

```{r}
ans <- flights[, .(delay_arr = arr_delay, delay_dep = dep_delay)]
head(ans)
```

### Compute or *do* by `j`

a) How many trips have had total delay < 0?

```{r}
ans <- flights[, sum( (arr_delay + dep_delay) < 0 )]
ans
```

The `j` expression can handle more than just selecting columns. As columns can be referred to as if they are variables, we can use then in *expressions*, i.e., calculating new values from them. Here, we simply calculate the sum of the two delay variables, and then use this to select rows with positive delays. 

### Subset by `i` *and* do by `j`

a) Calculate the average arrival and departure delay for all flights with "JFK" as the origin airport in the month of June.

```{r}
ans <- flights[origin == "JFK" & month == 6,
               .(m_arr = mean(arr_delay), m_dep = mean(dep_delay))]
ans
```

This first finds *row indices* where `origin` airport equals `"JFK"`, and `month` equals `6`. Then, it uses `j` to select two columns and calculate the mean. 

b) How many trips were made from "JFK" airport in the month of June?

```{r}
ans <- flights[origin == "JFK" & month == 6, length(dest)]
ans
```

The function `length()` requires an input argument to calculate the number of rows in the subset. We've used the destination column (`dest`), but could have used any column here. This syntax is the equivalent of SQL's: `SELECT COUNT(dest) FROM flights WHERE origin = 'JFK' AND month = 6`.

As this operation (counting observations corresponding to some condition) is quite common, **data.table** has a short=hand for it (`.N`). So we can carry out the same query as follows:

```{r}
ans <- flights[origin == "JFK" & month == 6L, .N]
ans
```

### Selecting columns stored in a variable

If you've stored the desired columns in a character vector, there are two options: 
a) Select columns named in a variable using the `..` prefix

```{r j_cols_dot_prefix}
select_cols = c("arr_delay", "dep_delay")
flights[ , ..select_cols]
```

b) Select columns named in a variable using `with = FALSE`

```{r j_cols_with}
flights[ , select_cols, with = FALSE]
```

c) We can also *deselect* columns using `-` or `!`. For example:

```{r eval = FALSE}
# returns all columns except arr_delay and dep_delay
ans <- flights[, !c("arr_delay", "dep_delay")]
# or
ans <- flights[, -c("arr_delay", "dep_delay")]
```

d) we can also select a range of variables by specifying the start and end column names, e.g., `year:day` to select the first three columns.

```{r eval = FALSE}
# returns year,month and day
ans <- flights[, year:day]
# returns day, month and year
ans <- flights[, day:year]
# returns all columns except year, month and day
ans <- flights[, -(year:day)]
ans <- flights[, !(year:day)]
```


## Aggregating data

We'll now look at how to combine the `i` and `j` methods described above with with `by` to perform operations *by group*. This is very similar to **dplyr**'s `group_by` function to do split-apply-combine. 

### Grouping using `by`

a) Get the number of trips corresponding to each of the three origin airports

```{r}
ans <- flights[, .(.N), by = .(origin)]
ans
```

Some things to note: 

- This preserves the order of the groups in the original data, rather than reordering them alphabetically
- Since we did not provide a name for the column returned in `j`, it was named `N`  automatically by recognizing the special symbol `.N`.
- if there is only one column or expression to refer to in `j` and `by`, we can drop the `.()` notation. This is purely for convenience. We could instead do:

```{r}
ans <- flights[, .N, by = origin]
ans
```

b) Calculate the number of trips for each origin airport for carrier code `"AA"` 

The unique carrier code `"AA"` corresponds to *American Airlines Inc.*

```{r}
ans <- flights[carrier == "AA", .N, by = origin]
ans
```

c) Get the total number of trips for each `origin, dest` pair for carrier code `"AA"`

```{r}
ans <- flights[carrier == "AA", .N, by = .(origin, dest)]
head(ans)
```

- `by` can take multiple columns, it will then group by all existing pairs of values

d) Get the average arrival and departure delay for each `orig,dest` pair for each month for carrier code `"AA"`? {#origin-dest-month}

```{r}
ans <- flights[carrier == "AA",
        .(mean(arr_delay), mean(dep_delay)),
        by = .(origin, dest, month)]
ans
```

- Since we did not provide column names for the expressions in `j`, they were automatically generated as `V1` and `V2`.

e) Do the same selection, but order the result by those grouping columns `origin`, `dest` and `month`

The choice to have `data.table` retain the original order of groups is intentional and by design. If you need to sort by groups, then you can simply replace `by` with `keyby` (note we also add more meaningful column names):

```{r}
ans <- flights[carrier == "AA",
        .(m_arr = mean(arr_delay), m_dep = mean(dep_delay)),
        keyby = .(origin, dest, month)]
ans
```

Note that output of **data.table** can be used in any other functions. For example, we can use **ggplot2** to plot the changing mean delay times by month:

```{r}
library(ggplot2)
ggplot(ans, aes(x = month, y = m_arr, col = dest)) + geom_line() + facet_wrap(~origin)
```

Note that we can also use the pipe operator (`%>%`) that we used with **dplyr** to pass the selected data to **ggplot2** or any other function. Here, we select calculate the departure delay for all flights to Dallas Fort Worth. Note that we need to load the **magrittr** package to make this work. 
```{r}
library(magrittr)
flights[dest == "DFW",
        .(m_dep = mean(dep_delay)),
        keyby = .(origin, dest, month)] %>%
  ggplot(aes(x = month, y = m_dep, col = origin)) + geom_line()
```

### Expressions in `by`

a) If we include conditional statements in the `by` section, this will then find a set of groups based on those conditions. For example, the following finds all observations where the departure delay is positive, and a second group where this value is 0 or less:

```{r}
ans <- flights[, .N, .(dep_delay>0)]
ans
```

With multiple conditions, this finds all pairs of conditions. It's probably easier to see this with an example -  let's find out how many flights started late but arrived early (or on time), started and arrived late etc...

```{r}
ans <- flights[, .N, .(dep_delay>0, arr_delay>0)]
ans
```

### Working with multiple columns in `j`

Previously, we used the `j` expression to calculate the mean of a couple of variables (with and without `i` expressions). But what if we had a large number of variables? Obviously, we can through one-by-one, but fortunately, **data.table** provides a symbol to facilitate this; `.SD`. This stands for **S**ubset of **D**ata, and is itself a `data.table` that holds the data for *the current group* defined using `by`. To see what this looks like, let's use the small data table we created earlier (`DT`):

```{r}
DT

DT[, print(.SD), by = ID]
```

Note that in this output, `.SD` contains all the original variables/columns *except the grouping columns*. It has also formed the groups that we specified using `by`. The last thing you need to know about this, is that this corresponds to a list, where element of the list is the subset of the original data table that corresponds to a grouping level. Phew. 

Now we can take advantage of a basic R function `lapply()`. This is another type of `apply()` function. We have previous used these for *applying* a function to the rows or columns of a data frame. `lapply()` allows us to apply a function to the different elements of a list. So, the following will estimate the mean of each column in `DT` on a group-wise basis:

```{r}
DT[, lapply(.SD, mean), by = ID]
```

We are almost there. There is one little thing left to address. In our `flights` `data.table`, we want to calculate the `mean()` of two columns `arr_delay` and `dep_delay`. But `.SD` would contain all the columns other than the grouping variables by default. In this case, we include the `.SDcols` argument to specify which columns to use. For example, `.SDcols = c("arr_delay", "dep_delay")` ensures that `.SD` contains only these two columns for each group. Note that you can also use `-` or `!` to specify which columns to remove from `.SD`. 

```{r}
flights[carrier == "AA",                       ## Only on trips with carrier "AA"
        lapply(.SD, mean),                     ## compute the mean
        by = .(origin, dest, month),           ## for every 'origin,dest,month'
        .SDcols = c("arr_delay", "dep_delay")] ## for just those specified in .SDcols
```

## Summary

The general form of `data.table` syntax is:

```{r eval = FALSE}
DT[i, j, by]
```

We have seen so far that,

#### Using `i`: {.bs-callout .bs-callout-info}

* We can subset rows similar to a `data.frame`- except you don't have to use `DT$` repetitively since columns within the frame of a `data.table` are seen as if they are *variables*.

* We can also sort a `data.table` using `order()`, which internally uses `data.table`'s fast order for performance.

We can do much more in `i` by keying a `data.table`, which allows blazing fast subsets and joins. We will see this in the *"Keys and fast binary search based subsets"* and *"Joins and rolling joins"* vignette.

#### Using `j`: {.bs-callout .bs-callout-info}

1. Select columns the `data.table` way: `DT[, .(colA, colB)]`.

2. Select columns the `data.frame` way: `DT[, c("colA", "colB")]`.

3. Compute on columns: `DT[, .(sum(colA), mean(colB))]`.

4. Provide names if necessary: `DT[, .(sA =sum(colA), mB = mean(colB))]`.

5. Combine with `i`: `DT[colA > value, sum(colB)]`.

#### Using `by`: {.bs-callout .bs-callout-info}

* Using `by`, we can group by columns by specifying a *list of columns* or a *character vector of column names* or even *expressions*. The flexibility of `j`, combined with `by` and `i` makes for a very powerful syntax.

* `by` can handle multiple columns and also *expressions*.

* We can `keyby` grouping columns to automatically sort the grouped result.

* We can use `.SD` and `.SDcols` in `j` to operate on multiple columns using already familiar base functions. Here are some examples:

    1. `DT[, lapply(.SD, fun), by = ..., .SDcols = ...]` - applies `fun` to all columns specified in `.SDcols` while grouping by the columns specified in `by`.

    2. `DT[, head(.SD, 2), by = ...]` - return the first two rows for each group.

    3. `DT[col > val, head(.SD, 1), by = ...]` - combine `i` along with `j` and `by`.

## Reshaping with **data.table**

We have previously encountered reshaping with **ggplot2**, where we needed to convert a short and fat data frame to a long and thin one. **data.table** also includes an implementation of a `melt` and `dcast` functions specifically designed to work with large in-memory data (e.g. 10Gb).

### `melt`ing `data.table`s (wide to long)

Let's create a small `data.table` containing some information about 5 families, including an ID, mother's age and the date of birth of their children:

```{r}
s1 <- "family_id age_mother dob_child1 dob_child2 dob_child3
1         30 1998-11-26 2000-01-29         NA
2         27 1996-06-22         NA         NA
3         26 2002-07-11 2004-04-05 2007-09-02
4         32 2004-10-10 2009-08-27 2012-07-21
5         29 2000-12-05 2005-02-28         NA"
DT <- fread(s1)
DT
str(DT)
```

To convert this to a *long* form where each `dob` is a separate observation, we can use the `melt()` function, specifying which variables we want to use as IDs (`id.vars`) and which to use as values (`measure.vars`):

```{r}
DT.m1 = melt(DT, id.vars = c("family_id", "age_mother"),
                measure.vars = c("dob_child1", "dob_child2", "dob_child3"))
DT.m1
str(DT.m1)
```

Note that the *molten* columns are automatically named `variable` and `value`. We can give these more informative names as follows: 

```{r}
DT.m1 = melt(DT, measure.vars = c("dob_child1", "dob_child2", "dob_child3"),
               variable.name = "child", value.name = "dob")
DT.m1
```

### `dcast`ing `data.table`s (long to wide)

In the previous section, we saw how to get from wide form to long form. Let's see the reverse operation in this section. Basically, what we wish to do is to collect all *child* observations corresponding to each `family_id, age_mother` into the same row. This can be done with the `dcast` function as follows:

```{r}
dcast(DT.m1, family_id + age_mother ~ child, value.var = "dob")
```


You can also pass a function to aggregate by in `dcast` with the argument `fun.aggregate`. This is particularly essential when the formula provided does not identify single observation for each cell.

```{r}
dcast(DT.m1, family_id ~ ., fun.agg = function(x) sum(!is.na(x)), value.var = "dob")
```

Check `?dcast` for other useful arguments and additional examples.

## Exercise

We'll use the dataset *Temperature.csv*, a file with sea temperature and salinity recorded from 31 stations over 15 years. The stations are located in one of 10 areas. Download this file, move it to your working directory and read it into R.You should submit the results as an R script with the commands you used, and a Word (or equivalent) with any results or figures *or* as an html page generated from an R Markdown document

Using this dataset and the functions introduced in this lab, do the following:

- Read in the data using `fread`
- Extract all winter observations
- Extract all winter observations for zone NC
- Select only the columns `Area`, `Season` and `Temperature`
- Select only the columns `Area` and `Temperature` but only for winter observations
- Find the total number of observations in winter
- Calculate the mean temperature and mean salinity in winter (Note that there are missing values so will have to use `na.rm = TRUE`)
- Find the number of observations per station in winter
- Find the number of observations per station per season
- Estimate average temperatures by month
- Estimate average temperatures by month by area
- Plot the output of the previous question using **ggplot2** using the `geom_line()` geometry

## Files used in lab

### *iris.csv* 

Fisher's Iris morphology dataset

| Column header | Variable |
| --- | --- |
| Sepal.Length | Sepal length (mm) |
| Sepal.Width | Sepal width (mm) |
| Petal.Length | Petal length (mm) |
| Petal.Width | Petal width (mm) |
| Species | Species name |
| Code | Species code |

### *flights14.csv*

Dataset of flights leaving New York airports in 2014

| Column header | Variable |
| --- | --- |
| year | Year |
| month | Month |
| day | Day of month |
| dep_delay | Departure delay (mins) |
| arr_delay | Arrival delay (mins) |
| carrier | Airline |
| origin | Departure airport |
| dest | Destination airport |
| air_time | Time in air (mins) |
| distance | Distance (miles) |

### *Temperature.csv*

Dutch ocean monitoring dataset

| Column header | Variable |
| --- | --- |
| Sample | Sample ID |
| Date | Date |
| DateNr | Date (different format) |
| dDay1 |  |
| dDay2 |  |
| dDay3 |  |
| Station | Station ID |
| Area | Station region |
| X31UE_ED50 | Easting |
| X31UN_ED50 | Northing |
| Year | Year |
| Month | Month |
| Season | Season |
| Salinity | Salinity (psu) |
| Temperature | Temperature (C) |
| CHLFa | Chlorophyll-a conc. |

[btsID]: http://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236) 
[dtmacID]: https://github.com/Rdatatable/data.table/wiki/Installation
